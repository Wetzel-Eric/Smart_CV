# My RAG Project

# ğŸš€ RAG Pipeline pour CV Matching

Une application Streamlit pour analyser des CVs et rÃ©pondre aux questions des recruteurs en utilisant un pipeline RAG (Retrieval-Augmented Generation).

## ğŸ“¦ Installation

1. Cloner le dÃ©pÃ´t :
   ```bash
   git clone https://github.com/Wetzel-Eric/Smart_CV.git
   cd rag-cv-matching


2. Installer les dÃ©pendances :
poetry install


3. Configurer .env :
cp .env.example .env

Ajoutez vos clÃ©s API dans .env.

## ğŸƒ Utilisation
Lancer l'application :
streamlit run app/main.py

## ğŸ§ª Tests
ExÃ©cuter les tests unitaires :
pytest tests/

## ğŸ“‚ Structure du Projet
.
â”œâ”€â”€ app/                  # Frontend Streamlit
â”œâ”€â”€ core/                 # Logique mÃ©tier
â”œâ”€â”€ components/           # Composants rÃ©utilisables
â”œâ”€â”€ config/               # Configuration
â”œâ”€â”€ data/                 # DonnÃ©es (PDFs, index Chroma)
â”œâ”€â”€ monitoring/           # ObservabilitÃ©
â”œâ”€â”€ tests/                # Tests
â””â”€â”€ docs/                 # Documentation

## ğŸ”§ Configuration
Modifier config/settings.py pour ajuster :
- pdf_path : Chemin vers le PDF Ã  analyser.
- chunk_size/chunk_overlap : ParamÃ¨tres de dÃ©coupage du texte.
- llm_model : ModÃ¨le LLM utilisÃ© (ex: mistral-large-latest).

---

### **12.2. `docs/architecture.md`**
```markdown
# Architecture du Pipeline RAG

## 1. Couches Principales

### 1.1. Frontend (`app/`)
- **Streamlit** : Interface utilisateur pour interagir avec le pipeline.
- **Services** : Couche d'abstraction entre l'UI et le mÃ©tier (ex: `bootstrap_service.py`).

### 1.2. MÃ©tier (`core/`)
- **Orchestrateur** : Coordination des Ã©tapes du pipeline RAG.
- **Bootstrap** : Initialisation des composants et du pipeline.

### 1.3. Composants (`components/`)
- **Reader** : Chargement des documents (PDF).
- **Chunker** : DÃ©coupage des documents en chunks.
- **Embedder** : GÃ©nÃ©ration d'embeddings pour les chunks.
- **Retriever** : RÃ©cupÃ©ration des contextes pertinents (Chroma).
- **Generator** : GÃ©nÃ©ration de rÃ©ponses (LLM).

### 1.4. Infrastructure (`monitoring/`, `config/`)
- **TruLens** : ObservabilitÃ© et feedbacks.
- **Configuration** : ParamÃ¨tres centralisÃ©s.


3. Points ClÃ©s

- **Injection de dÃ©pendances** : Via dependency_injector pour une meilleure testabilitÃ©.
- **Cache des embeddings** : Persistance de l'index Chroma pour Ã©viter les recalculs.
- **Gestion des erreurs** : Retries exponentiels et validation des entrÃ©es.
- **DÃ©couplage UI/MÃ©tier** : Les services (app/services/) isolent Streamlit du code mÃ©tier.



## Objectif
Ce projet implÃ©mente un systÃ¨me RAG (Retrieval-Augmented Generation) pour fournir des rÃ©ponses contextuelles Ã  partir d'un corpus de documents.

Documentation technique â€“ Projet Sales RAG
Architecture
- Description : Le projet utilise un backend/API sÃ©parÃ© avec une UI Streamlit stateless.
- Axe dâ€™amÃ©lioration : Architecture solide. VÃ©rifier que la sÃ©paration backend/frontend est maintenue pour futures Ã©volutions.

Gestion multi-utilisateurs
- Description : Les sessions sont isolÃ©es et la mÃ©moire conversationnelle est gÃ©rÃ©e par utilisateur.
- Axe dâ€™amÃ©lioration : Fonctionnel, mais prÃ©voir un stockage persistant et scalable (exâ€¯: Redis ou Pinecone) pour gÃ©rer un usage concurrent Ã©levÃ©.

Gestion des API Keys / Secrets
- Description : Les clÃ©s API sont gÃ©rÃ©es via un secrets manager ou des variables dâ€™environnement.
- Axe dâ€™amÃ©lioration : OK. Assurer la rotation rÃ©guliÃ¨re des clÃ©s et la sÃ©curitÃ© sur les dÃ©ploiements cloud.

Streaming LLM
- Description : Streaming optimisÃ© avec buffering pour lâ€™UI afin dâ€™amÃ©liorer lâ€™expÃ©rience utilisateur.
- Axe dâ€™amÃ©lioration : OK. Pour de trÃ¨s longs prompts, ajuster la frÃ©quence des mises Ã  jour pour rÃ©duire la charge sur lâ€™UI.

Historique & mÃ©moire conversationnelle
- Description : MÃ©moire persistante avec token limit et mÃ©canisme de pruning.
- Axe dâ€™amÃ©lioration : OK. Surveiller la croissance de la mÃ©moire pour les longues sessions et prÃ©voir un mÃ©canisme dâ€™archivage si nÃ©cessaire.

Logging & monitoring
- Description : Logs structurÃ©s avec mÃ©triques de latence et suivi des erreurs.
- Axe dâ€™amÃ©lioration : OK. Ajouter Ã©ventuellement de lâ€™alerting automatique pour les erreurs critiques ou latence Ã©levÃ©e.

Tests & maintainabilitÃ©
- Description : Tests unitaires et tests dâ€™intÃ©gration avec typage Python fort.
- Axe dâ€™amÃ©lioration : OK. Maintenir la couverture tests et ajouter des tests dâ€™intÃ©gration multi-utilisateur si possible.

UI Streamlit
- Description : Interface minimaliste, responsive, offrant une expÃ©rience utilisateur fluide.
- Axe dâ€™amÃ©lioration : OK. VÃ©rifier la performance de lâ€™UI mÃªme pour de longues sessions ou des rÃ©ponses LLM volumineuses.

Support multi-LLM
- Description : Le backend permet de gÃ©rer plusieurs modÃ¨les LLM.
- Axe dâ€™amÃ©lioration : OK. PrÃ©voir des tests de compatibilitÃ© et un monitoring de performance par modÃ¨le.

DÃ©ploiement / production readiness
- Description : Projet dÃ©ployÃ© via Docker, avec CI/CD et monitoring.
- Axe dâ€™amÃ©lioration : OK. Effectuer des tests de charge et prÃ©voir le scaling automatique pour plusieurs utilisateurs simultanÃ©s.

ExpÃ©rience utilisateur (UX)
- Description : UX optimisÃ©e, responsive et gestion des erreurs.
- Axe dâ€™amÃ©lioration : OK. AmÃ©liorer les messages utilisateurs en cas de timeout LLM ou erreurs rÃ©seau.

ExtensibilitÃ©
- Description : Architecture modulaire facilitant lâ€™ajout de nouveaux modÃ¨les ou pipelines RAG.
- Axe dâ€™amÃ©lioration : OK. VÃ©rifier la modularitÃ© pour futurs agents ou sources de donnÃ©es additionnelles.

## HF Embedding

Objectifs:
Lazy instantiation :
    - On ne crÃ©e lâ€™objet HuggingFaceEmbeddings quâ€™au moment de lâ€™utilisation (embed) pour ne pas charger inutilement le modÃ¨le en mÃ©moire dÃ¨s lâ€™instanciation.

Batching :
    - DÃ©couper les textes en batch pour Ã©viter les problÃ¨mes de mÃ©moire ou de timeout avec de grands corpus.

Gestion dâ€™erreurs / fallback :
    - Si embed_documents plante, on ne veut pas arrÃªter tout le pipeline.
    - Retourner des vecteurs nuls pour le batch problÃ©matique.

Async-friendly :
    - La mÃ©thode embed est async pour pouvoir lâ€™intÃ©grer dans un pipeline async (CLI, Streamlit, LLMGenerator, etc.).

##  ChromaRetriever
Objectifs:
Wrapper Chroma VectorStore :
    - Indexer les textes avec des embeddings.
    - Permettre ensuite la recherche par similaritÃ©.

CompatibilitÃ© async :
    - Appel Ã  embedder.embed qui est async.

Robustesse minimale :
    - VÃ©rifie que la base Chroma est initialisÃ©e avant de rÃ©cupÃ©rer.

SimplicitÃ© / rÃ©utilisabilitÃ© :
    - Peut Ãªtre utilisÃ© dans diffÃ©rents pipelines (CLI, Streamlit, LLMGenerator, etc.) sans changement.

## Structure du projet
- `data/` : corpus, donnÃ©es brutes et nettoyÃ©es
- `index/` : indexes vectoriels pour retrieval
- `src/` : code source et pipeline
- `notebooks/` : exploration et tests
- `models/` : modÃ¨les et embeddings sauvegardÃ©s
- `scripts/` : scripts pour automatisation
- `tests/` : tests unitaires et d'intÃ©gration
- `docs/` : documentation technique


## Pipeline RAG - vue modulaire
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDFReader â”‚  â† Reader (async)
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ list[Document]
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚RecursiveChunkerâ”‚  â† Chunker (async)
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ list[Document w/ chunks]
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   HFEmbedding    â”‚  â† Embeddings
â”‚  async.embed()   â”‚
â”‚  model_instance  â”‚ â†’ sync object pour Chroma
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ embeddings (sync pour Chroma)
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ChromaRetriever  â”‚  â† Retriever
â”‚  from_texts()    â”‚  (sync)
â”‚  similarity_searchâ”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ list[str] context
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLMGenerator     â”‚  â† Generator modulable
â”‚  prompt_strategy â”‚
â”‚  generate_stream â”‚ â†’ Streamlit / UI
â”‚  generate        â”‚ â†’ CLI
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ answer string
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLI / UI    â”‚
â”‚ print() /   â”‚
â”‚ Streamlit   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



## Installation
```bash
pip install -r requirements.txt



